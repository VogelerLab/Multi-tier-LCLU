#####################################################################################################################
# Title: LCLUC project model training and validation script
# ---------------------------------------------------------
# This script reads a set of reference data (training and validation) and train and test a Random Forest (RF)
# model for specified selected features. Reference data are generated by MakeSampleData.py script and selected
# features are picked after inspecting AnalyzeFeatures.py script. It then creates a table of validation results
# to be used for area-based map accuracy assessment via another script.Note that models can be trained on any
# desired combination of years or all available years, but will be validated for each year separately.
#
# Required input data:
#   - Training and validation datasets (two sets of .p and .txt files) created by MakeSampleData.py
#   - Training and validation data labels (two .csv file) created manually by interpreters
# Generated output file(s):
#   - Trained Random Forest classifier model (.joblib file) and its companion .txt file containing model
#     configuration and performance evaluation data
#   - A .txt file containing model performance on validation data
#   - A .csv file containing predicted and reference labels for validation point, which will be used for
#     mop accuracy assessment by corresponding python script
#
# Note: Variables in the variables setting block are set to the values used in the last program run and may not
#       represent the values used to create the files given in the SampleData folder.
####################################################################################################################
# Shahriar S. Heydari, Vogeler Lab, 4/24/2024

import pickle
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split
import joblib

# Variables setting block
##########################
# input features specification (file name, desired features to extract, and time-series reduction method)
train_data_file_name = 'SA_urbanTrainSet'
val_data_file_name = 'SA_urbanValidationSet'
# features_to_pick = 'all' # or specify as a dictionary with a specific name for feature set
features_to_pick = {'name': 'SA_finalModel',
 'features': ['VV_YearMean', 'VV_YearRange', 'B3_YearMin', 'tcb_YearMin', 'B12_YearMin', 'tcg_YearMean',
              'B12_YearMean', 'ndvi_YearMin', 'mndwi_YearMax', 'nbai_YearMin', 'uci_YearMean', 'B2_YearMax',
              'wi_YearMax', 'nbai_YearMax', 'B3_YearRange', 'B8_YearRange', 'tcw_YearRange', 'tca_YearRange',
              'bai_YearRange', 'nbai_YearRange', 'VV_stdev_5x5', 'B3_stdev_3x3', 'B8_savg_5x64', 'B8_stdev_5x5',
              'tcg_stdev_5x5', 'tcw_stdev_3x3', 'VV_prom_5x64', 'VV_corr_5x64', 'VV_shade_5x64', 'VV_imcorr2_9x64',
              'VV_shade_9x64', 'B8_contrast_9x64', 'B8_corr_5x64', 'B8_imcorr2_5x64', 'B8_shade_5x64',
              'B8_imcorr1_9x64', 'B8_shade_9x64', 'ntl_data', 'water_percentage', 'total_year_rain', 'bio_06',
              'bio_05', 'bio_10', 'bio_04', 'bio_03', 'bio_17', 'bio_15', 'slope', 'aspect', 'soil_data', 'ECO_ID'] }
reduceTSflag = 1
# if 0, median value of all yearly observations are used,
# if 1, the min/mean/max/range yearly values are calculated and used,
# if 2, the observation closest to selectDOY elements are used.
selectDOY = np.array([106, 288])/366  # (15, 106, 197, 288 for 4 seasons)

# reference labels file specification
train_labels_file_name = 'SA_urbanTrainSetLabels.csv'
val_labels_file_name = 'SA_urbanValidationSetLabels.csv'
response_columns = ['LCP_16', 'LCP_17', 'LCP_18', 'LCP_19', 'LCP_20']
confidence_columns = ['conf_2016', 'conf_2017', 'conf_2018', 'conf_2019', 'conf_2020']
# list of confidence values to consider (other terms will not be included in analysis)
conf_to_pick = ['High','high','Low','low']
# you can combine labels to make a more general label through a dictionary definition here. for example, you can
# # set combine_labels = {'Impervious': ['Building', 'Pavement'], 'Vegetation': ['Short_vegetation', 'Tall_vegetation']}
combine_labels = None
labels_first_year = 2016
labels_number_of_years = 5

# train/test parameters definition
test_size = 0.2           # Note: test_size should be scalar, but multiple train_sizes are allowed
test_years = 'all'        # either 'all' or list of years (or a list of just one year)
train_sizes = [0.8]       # multiple training ratios can be specified as a list
train_years = 'all'       # either 'all' or list of years (or a list of just one year)
validation_years = 'all'  # either 'all' or list of years (or a list of just one year)
# Note: If you define specific years for test and train, the two lists should be mutually exclusive.

# if num_train_points_groups > 0, each training point is assigned a random group number between zero and
# num_train_points_groups in such a way that the total number of points in the groups are almost the same. This
# capability is useful if you want to do a k-fold cross-validation later.
num_train_points_groups = 0

# Random Forest classifier definition
n_estimators = 100
min_samples_leaf = 3
clf = RandomForestClassifier(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, class_weight='balanced_subsample')

# other variables
num_training_iterations = 3
outputFolder = ''
save_flattened_labels = False

################################################################################################################
# Helper functions
################################################################################################################

def closest(lst, K):
    # will be used to pick suitable time stamps in case reduceDate != 0
    lst = np.asarray(lst)
    idx = (np.abs(lst - K)).argmin()
    return idx

def generate_sample_wrapper_function(allPoints_allFeatures, all_feature_names):
    # wrapper function to help generating yearly stratified samples for each train and test set. This function calls
    # generate_samples function to create the final training and test data.
    # Note: It is assumed that the first four columns of matrix allPoints_allFeatures are 'PointID', 'XLon', 'YLat',
    # and 'Year', and the last column is 'Label.

    # as input matrix has one row for each point for each year, we first select just one year of data
    # to partition the points to train and test points so the train and test data will be spatially disjoint
    # (but they can share data from the same year)
    year_ind = 3
    label_ind = -1
    points_base = allPoints_allFeatures[allPoints_allFeatures[:,year_ind] == labels_first_year,]

    # do stratified sampling to pick test points
    p_rest, p_test, y_rest_p, y_test_p = train_test_split(points_base[:, 0], points_base[:, label_ind],
                                                          test_size=test_size, stratify=points_base[:, label_ind])

    p_train_list = []
    # for each train size specified in the input train size list, an updated ratio is calculated to
    # adjust the initial value to the number of points available after setting aside the test points
    updated_train_sizes = [train_size * len(points_base) / len(p_rest) for train_size in train_sizes]
    # for each train size do the stratified sampling to pick training points
    for train_size in updated_train_sizes:
        if train_size >= 1:  # the last train_size calculation may get bigger than 1 due to rounding errors,
            # so just use the "rest" of points in such a case
            p_train = p_rest
        else:
            p_train, p_unused, y_train_p, y_unused_p = train_test_split(p_rest, y_rest_p,
                                                                        train_size=train_size, stratify=y_rest_p)
        # create point groups if num_train_points_groups > 0, or add a vector of all zeros
        p_train_group = np.zeros(p_train.shape[0])
        if num_train_points_groups > 0:
            bin_size = int(p_train.shape[0] / num_train_points_groups)
            for i in range(num_train_points_groups - 1):
                p_train_group[i * bin_size:(i + 1) * bin_size] = i
            p_train_group[(num_train_points_groups - 1) * bin_size:] = num_train_points_groups-1
        p_train = np.hstack((p_train[:,np.newaxis], p_train_group[:,np.newaxis]))
        p_train_list.append(p_train)

    # now we have an array containing test points (p_test) and a list of arrays containing training points for each
    # train size (p_train_list). These lists are passed along with input features matrix to the sampling function
    X_train_list, y_train_list, g_train_list, X_test, y_test, features_names = \
        generate_samples(p_train_list, p_test, allPoints_allFeatures, all_feature_names)

    # returning variables include:
    # X_train_list: A list containing training features matrix for each selected train size
    # y_train_list: point labels corresponding to X_train_list items
    # g_train_list: point group numbers corresponding to X_train_list items
    # X_test: test data features matrix
    # y_test: test data labels
    # features_names: A list containing name of features in the features matrix
    return X_train_list, y_train_list, g_train_list, X_test, y_test, features_names

def generate_samples(train_points_list, test_points, allPoints_allFeatures, all_feature_names):
    # function to extract yearly samples for selected points from globally defined allPoints_allFeatures variable.
    # Features can be dropped or selected as well by setting related variables.
    # test_points is a list of test point IDs,
    # train_points_list is a list of arrays including train point IDs and their group numbers.
    # Note: It is assumed that the first four columns of matrix allPoints_allFeatures are 'PointID', 'XLon', 'YLat',
    # and 'Year', and the last column is 'Label.

    # Below array is duplicate array for test samples (arrays will be reduced later by dropping unwanted points/years)
    test_features = np.copy(allPoints_allFeatures)
    # Look at each point's available samples and decide to drop some of them from test samples or not.
    # If a fixed train year is specified, that year's sample will be dropped from test samples. Otherwise,
    # all years are used for testing.
    # keep_ind is the variable used to flag qualified entries. Those entries that will remain zero after the loop will
    # be dropped, including all entries related to the TEST points.
    keep_ind = np.zeros(test_features.shape[0])
    for pID in test_points:
        if test_years != 'all':
            ind = []
            for year in test_years:
                loc = np.where(np.logical_and(test_features[:, 0] == pID, test_features[:, 3] == year))[0].tolist()
                ind = ind + loc
        else:
            ind = np.where(test_features[:, 0] == pID)[0]
        keep_ind[ind] = 1
    # drop non-qualified entries
    entries_to_drop_test = np.where(keep_ind == 0)[0]
    test_features = np.delete(test_features, entries_to_drop_test, axis=0)
    # randomise samples
    np.random.shuffle(test_features)
    # drop point ID, coordinate, and year from features to create train/test data vectors and targets for
    # classification. Output feature names will be updated as well.
    X_test = test_features[:, feature_start_index:label_ind]
    y_test = test_features[:, label_ind]
    features_out = all_feature_names[feature_start_index:label_ind]

    X_train_list = []
    y_train_list = []
    g_train_list = []
    # Now do the same for each set of training points
    for train_points in train_points_list:
        train_features = np.copy(allPoints_allFeatures)
        group_features = np.zeros(train_features.shape[0])
        keep_ind = np.zeros(train_features.shape[0])
        for pID, group in train_points:
            if train_years != 'all':
                ind = []
                for year in train_years:
                    loc = np.where(np.logical_and(train_features[:, 0] == pID, train_features[:, 3] == year))[0].tolist()
                    ind = ind + loc
            else:
                ind = np.where(train_features[:, 0] == pID)[0]
            keep_ind[ind] = 1
            group_features[ind] = group
        entries_to_drop_train = np.where(keep_ind == 0)[0]
        train_features = np.delete(train_features, entries_to_drop_train, axis=0)
        group_features = np.delete(group_features, entries_to_drop_train, axis=0)
        rnd_index = np.arange(train_features.shape[0])
        np.random.shuffle(rnd_index)
        train_features = train_features[rnd_index]
        group_features = group_features[rnd_index]
        X_train = train_features[:, feature_start_index:label_ind]
        y_train = train_features[:, label_ind]
        X_train_list.append(X_train)
        y_train_list.append(y_train)
        g_train_list.append(group_features)

    return X_train_list, y_train_list, g_train_list, X_test, y_test, features_out

def reduce_time_series(time_series, band_names_in, TS_index, flag):
    # function to reduce time series into aggregate values

    if flag == 0:  # make the median of all observations
        reduced_time_series = np.median(time_series, axis=0)
        band_names_out = band_names_in
    elif flag == 1: # extract min/max/mean/range statistics
        try:
            _min = np.nanmin(time_series, axis=0)
            _mean = np.nanmean(time_series, axis=0)
            _max = np.nanmax(time_series, axis=0)
            _range = _max - _min
        except:
            _min = np.array(np.repeat(np.nan, len(band_names_in)))
            _mean = _min
            _max = _min
            _range = 0
        _min_bands = [x + '_YearMin' for x in band_names_in]
        _mean_bands = [x + '_YearMean' for x in band_names_in]
        _max_bands = [x + '_YearMax' for x in band_names_in]
        _range_bands = [x + '_YearRange' for x in band_names_in]
        reduced_time_series = np.hstack((_min, _mean, _max, _range))
        band_names_out = _min_bands + _mean_bands + _max_bands  + _range_bands
    elif flag == 2:  # pick suitable observations and attach them together horizontally
        index = [closest(time_series[:, TS_index], l) for l in selectDOY]
        series_temp = []
        series_bands = []
        for k in range(len(index)):
            series_temp = series_temp + time_series[index[k]].tolist()
            series_bands = series_bands + [x + '_' + str(k) for x in band_names_in]
        reduced_time_series = np.array(series_temp)
        band_names_out = series_bands
    return reduced_time_series, band_names_out

def prepare_data(data_file_name, labels_file_name, features_to_pick, combine_labels):
    # function to read points reference labels and points extracted data from reference datasets and generate
    # a complete features matrix for all points and years. Each row in this matrix will contain all extracted
    # features for each point in one year.

    # reading points labels from csv file and process it to a flattened list (the input file has multiple years listed
    # in the same row for each point, i.e. each point is represented by one line. This structure is flattened and
    # the empty fields are filled and a flattened array is created in which each point and year have a separate row.
    ###############################################################################################################
    labels = pd.read_csv(labels_file_name)
    response_names = np.unique(labels.loc[:, response_columns[0]].dropna()).tolist()
    if combine_labels != None:
        response_names_new = response_names
        for new_label in list(combine_labels.keys()):
            response_names_new = [x if x not in combine_labels.get(new_label) else new_label for x in response_names_new]
        response_names_new_unique = np.unique(response_names_new).tolist()
    points_and_labels = []  # the full table of available points and labels for each year
    for i in labels.index:
        pID = labels.loc[i, 'pointID']
        first_confident_year_index = 0
        response_base_confidence = labels.loc[i, confidence_columns[first_confident_year_index]]
        while ((response_base_confidence not in conf_to_pick) or pd.isnull(response_base_confidence)) and (first_confident_year_index < labels_number_of_years-1):
            first_confident_year_index += 1
            response_base_confidence = labels.loc[i, confidence_columns[first_confident_year_index]]
        if ((response_base_confidence not in conf_to_pick) or pd.isnull(response_base_confidence)) and (first_confident_year_index == labels_number_of_years-1):
            continue
        response_base = labels.loc[i, response_columns[first_confident_year_index]] # retrieve the base response (for first year)
        response_base_index = response_names.index(response_base)
        for j in range(first_confident_year_index, labels_number_of_years):  # add other response values in subsequent years
            response_year = labels.loc[i, response_columns[j]]
            if pd.isnull(response_year):
                response_year = response_base
                response_year_index = response_base_index
            else:
                response_year_index = response_names.index(response_year)
            response_year_confidence = labels.loc[i, confidence_columns[j]]
            if pd.isnull(response_year_confidence):
                response_year_confidence = response_base_confidence
            if (response_year_confidence not in conf_to_pick):
                response_base_confidence = response_year_confidence
                continue
            if (response_year_confidence in conf_to_pick): # change label
                response_base = response_year
                response_base_index = response_names.index(response_year)
                response_base_confidence = response_year_confidence
            if combine_labels == None:
                points_and_labels.append([pID, labels_first_year + j, response_year_index])
            else:
                response_base_index_new = response_names_new_unique.index(response_names_new[response_year_index])
                points_and_labels.append([pID, labels_first_year + j, response_base_index_new])
    # convert list to numpy array
    points_and_labels = np.array(points_and_labels)

    if save_flattened_labels:
        pl = pd.DataFrame(points_and_labels, columns=['ID','Year','class'])
        pl.to_csv(outputFolder + 'labels_flattened.csv')
    # response_names will contain final assignment for reference label names after processing and label merging
    if combine_labels != None:
        response_names = response_names_new_unique

    # reading extracted features from pickle file
    #############################################
    point_data = pickle.load(open(data_file_name + '.p', 'rb'))

    # reading data configuration text file and parse it to get feature names and some other information
    ###################################################################################################
    with open(data_file_name + '.txt', 'r') as f:
        contents = f.read()
        # reading feature names
        p1 = contents.find('Sentinel-1 bands:')
        temp = contents[p1 + 18:]
        p2 = temp.find('\n')
        Sentinel1BandNames = eval(temp[:p2].strip())
        p1 = contents.find('Sentinel-2 bands:')
        temp = contents[p1 + 18:]
        p2 = temp.find('\n')
        Sentinel2BandNames = eval(temp[:p2].strip())
        p1 = contents.find('Annual bands:')
        temp = contents[p1 + 14:]
        p2 = temp.find('\n')
        annualBandNames = eval(temp[:p2].strip())
        p1 = contents.find('Static bands:')
        temp = contents[p1 + 14:]
        p2 = temp.find('\n')
        staticBandNames = eval(temp[:p2].strip())
    Sentinel1_TS_index = Sentinel1BandNames.index('timestamp')
    Sentinel2_TS_index = Sentinel2BandNames.index('timestamp')

    pointVector = []
    Sentinel1DataVector = []
    Sentinel2DataVector = []
    annualDataVector = []
    staticDataVector = []
    outputLabels = []

    # converting retrieved data from pickle file to the required 2-D features matrix structure
    ###########################################################################################
    for i in range(len(point_data)):
        # extracting data parts
        data = point_data[i]
        pID = data['point_ID']
        coord = data['coordinates']
        variable_data = data['variable_data']
        static_data = data['fixed_data']['static_data']

        N = len(variable_data)
        for j in range(N):
            year = variable_data[j]['year']
            try:
                label = points_and_labels[np.where(
                    np.logical_and(points_and_labels[:, 0] == pID, points_and_labels[:, 1] == year)), 2].item()
            except:
                continue

            Sentinel1_data = variable_data[j]['Sentinel1_data']
            Sentinel2_data = variable_data[j]['Sentinel2_data']

            # convert fractional year to DOY
            Sentinel1_data[:, Sentinel1_TS_index] = (366 * (Sentinel1_data[:, Sentinel1_TS_index] - year)).astype(int)
            Sentinel2_data[:, Sentinel2_TS_index] = (366 * (Sentinel2_data[:, Sentinel2_TS_index] - year)).astype(int)

            Sentinel1_data, Sentinel1NewBandNames = reduce_time_series(Sentinel1_data, Sentinel1BandNames,
                                                                   Sentinel1_TS_index, reduceTSflag)
            timestamp_indices = [Sentinel1NewBandNames.index(x) for x in Sentinel1NewBandNames if x.find('timestamp')>-1]
            Sentinel1_data = np.delete(Sentinel1_data, timestamp_indices)
            Sentinel1NewBandNames = [Sentinel1NewBandNames[x] for x in range(len(Sentinel1NewBandNames)) if x not in timestamp_indices]

            Sentinel2_data, Sentinel2NewBandNames = reduce_time_series(Sentinel2_data, Sentinel2BandNames,
                                                                     Sentinel2_TS_index,  reduceTSflag)
            timestamp_indices = [Sentinel2NewBandNames.index(x) for x in Sentinel2NewBandNames if
                                 x.find('timestamp') > -1]
            Sentinel2_data = np.delete(Sentinel2_data, timestamp_indices)
            Sentinel2NewBandNames = [Sentinel2NewBandNames[x] for x in range(len(Sentinel2NewBandNames)) if
                                   x not in timestamp_indices]

            annual_data = variable_data[j]['annual_data']

            pointVector.append([pID] + coord + [year])
            Sentinel1DataVector.append(Sentinel1_data)
            Sentinel2DataVector.append(Sentinel2_data)
            annualDataVector.append(annual_data)
            staticDataVector.append(static_data)
            outputLabels.append(label)

    outputFeatures = np.hstack((np.array(pointVector), np.array(Sentinel1DataVector), np.array(Sentinel2DataVector),
                                np.array(annualDataVector), np.array(staticDataVector),
                                np.array(outputLabels)[:,np.newaxis]))

    yearly_feature_names = Sentinel1NewBandNames + Sentinel2NewBandNames + annualBandNames
    static_feature_names = staticBandNames
    output_feature_names = ['PointID', 'XLon', 'YLat', 'Year'] + yearly_feature_names + static_feature_names + ['Label']

    if features_to_pick != 'all':
        pick_indices = [0,1,2,3] + [output_feature_names.index(i) for i in features_to_pick] + [label_ind]
        outputFeatures = outputFeatures[:, pick_indices]
        output_feature_names = ['PointID', 'XLon', 'YLat', 'Year'] + features_to_pick + ['Label']

    # now allPoints_allFeatures is a 2D numpy array containing all features for each point
    # remove rows with NaN values
    outputFeatures = outputFeatures[~np.isnan(outputFeatures).any(axis=1)]
    # shuffle it, in case we want to use it directly for cross-validation
    np.random.shuffle(outputFeatures)
    return response_names, outputFeatures, output_feature_names

def calculate_predictions(model, year, extracted_features):
    num_features = extracted_features.shape[1]-5    # first three are point id and coordinates, 4th is the year, and the last one is the label
    year_ind = 3
    points_base = extracted_features[extracted_features[:,year_ind] == labels_first_year,]
    output_array = []
    for pID in points_base[:, 0]:
        try:
            loc = np.where(np.logical_and(extracted_features[:, 0] == pID, extracted_features[:, 3] == year))[0][0]
            features = extracted_features[loc, :].tolist()
            output_array.append(features)
        except:
            # Will add all-zero features and -1 as label to keep the row for this pID/year in the table.
            # The predictions will not be used for assessment
            output_array.append([pID, 0, 0, year] + [0] * num_features + [label_ind])
    output_array = np.array(output_array)
    labels = output_array[:,label_ind]
    prediction = model.predict(output_array[:, feature_start_index:label_ind])
    null_indices = np.where(labels == -1)[0]
    prediction[null_indices] = -1

    return output_array[:,[0,3]], labels, prediction, np.delete(labels, null_indices), np.delete(prediction, null_indices)

##########################################################################################
# Main program
##########################################################################################

# 1. Model training and testing based on training data
#########################################################
# reading training data files and generating features matrix
response_names, extracted_features, feature_names = prepare_data(train_data_file_name, train_labels_file_name, features_to_pick['features'], combine_labels)
# NOTE: It is assumed that the first four columns of matrix extracted_features are 'PointID', 'XLon', 'YLat',
# and 'Year', and the last column is 'Label. Therefore, features are all other columns.
year_ind = 3
feature_start_index = 4
label_ind = -1
# write model training info in model configuration .txt file
model_name = features_to_pick['name']
print('Processing feature set {}:'.format(model_name))
config_file = open(outputFolder + model_name + '.txt','w')
config_file.write('Training data file: {}\n'.format(train_data_file_name))
config_file.write('Training labels data file: {}\n'.format(train_labels_file_name))
config_file.write('Train years: {}, Test years: {}\n'.format(train_years, test_years))
config_file.write('Number of trees: {}, minimum leaf size: {}\n'.format(n_estimators, min_samples_leaf))
config_file.write('Classification response labels: {}\n'.format(response_names))
config_file.write('Confidence to pick: {}\n'.format(conf_to_pick))
_, class_counts = np.unique(extracted_features[:,label_ind], return_counts=True)
config_file.write('All extracted samples class counts: {}, total: {}\n'.format(class_counts, np.sum(class_counts)))
config_file.write('Selected features: {}\n'.format(feature_names[feature_start_index:label_ind]))
scores = []
# model simulation is done for a number of iterations. In each iteration a new random set of training data is
# selected from input data pool and the model is trained and evaluated.
print('... running {} iterations ...'.format(num_training_iterations))
for c in range(num_training_iterations):
    # generating a new set of training data
    X_train_list, y_train_list, g_train_list, X_test, y_test, features_names = \
        generate_sample_wrapper_function(extracted_features, feature_names)
    # train model and do prediction and scoring
    clf.fit(X_train_list[0],y_train_list[0])
    y_pred = clf.predict(X_test)
    score = clf.score(X_test, y_test)
    scores.append(score)
# complete model evaluation reporting to the .txt file
config_file.write('Number of training iterations: {}\n'.format(num_training_iterations))
config_file.write('score mean: {:.2f}, min: {:.2f}, max: {:.2f}\n'.format(np.mean(scores), np.min(scores), np.max(scores)))
confusion = confusion_matrix(y_test, y_pred, labels=np.arange(len(response_names)))
report = classification_report(y_test, y_pred, digits=3, output_dict=True)
unwanted = {'accuracy', 'macro avg', 'weighted avg'}
for unwanted_key in unwanted: del report[unwanted_key]
f1_list = [report[key]['f1-score'] for key in report.keys()]
f1_min_index = f1_list.index(min(f1_list))
config_file.write('\nEvaluation set confusion matrix for last iteration (columns are predictions):\n{}\n'.format(confusion))
config_file.write('\nEvaluation set classification report for last iteration :\n{}\n'.format(classification_report(y_test, y_pred, digits=3)))
config_file.write(
    'Minimum F1 value: {:.3f} at class {}\n\n'.format(f1_list[f1_min_index], list(report.keys())[f1_min_index]))
print('Model {}: score mean: {:.2f}, min: {:.2f}, max: {:.2f}\n'.format(model_name, np.mean(scores), np.min(scores), np.max(scores)))
# now training model on all available data. first filter input data based on selected training year (if necessary).
if train_years != 'all':
    ind = []
    for year in train_years:
        loc = np.where(extracted_features[:, year_ind] == year)[0].tolist()
        ind = ind + loc
    extracted_features = extracted_features[ind,:]
# train the final model
trained_model = RandomForestClassifier(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, class_weight='balanced_subsample')
trained_model.fit(extracted_features[:,feature_start_index:label_ind], extracted_features[:,label_ind])
# calculate feature importance and record it in the configuration file
importances = list(zip(feature_names[feature_start_index:label_ind],trained_model.feature_importances_))
importances.sort(key=lambda x:x[1], reverse=True)
config_file.write('Feature importances:\n')
config_file.write('\n'.join('{:>16}: {:.3f}'.format(k[0], k[1]) for k in importances))
config_file.close()
# store trained model in a binary .joblib file
_ = joblib.dump(trained_model, outputFolder + model_name + '.joblib', compress=9)

# 2. Full trained model evaluation based on validation data
###########################################################
# reading validation data files and generating features matrix
response_names, extracted_features, feature_names = prepare_data(val_data_file_name, val_labels_file_name, features_to_pick['features'], combine_labels)
if validation_years == 'all':
    validation_years = np.unique(extracted_features[:,year_ind])
output_file = open(outputFolder + model_name + '_validation.txt', 'w')
data_to_export = [] # this variable will hold output validation .csv file data
columns_to_export = ['pID'] # this variable will hold output validation .csv file header line items
for yr in validation_years:
    columns_to_export += ['Ref_' + str(yr), 'Map_' + str(yr)]
# write model validation info in model configuration .txt file
output_file.write('Validation data file: {}\n'.format(val_data_file_name))
output_file.write('Validation labels file: {}\n'.format(val_labels_file_name))
output_file.write('Classification response labels: {}\n'.format(response_names))
output_file.write('Combine labels: {}\n'.format(combine_labels))
output_file.write('Picked confidences: {}\n'.format(conf_to_pick))
# do model evaluation for each year separately
for year in validation_years:
    output_file.write('\nValidation year: {}\n'.format(year))
    output_file.write('----------------------\n')
    print('...Validating year:', year)
    # calculate model predictions for a specific year
    # note: input remote sensing data may not be available for each point on each year, therefore a function
    # is needed to handle this prediction to return an array with the same number of rows regardless of the
    # chosen year.
    pIDs, labelsT, predictionsT, labels, predictions = calculate_predictions(trained_model, year,
                                                                             extracted_features)
    # complete model evaluation reporting to the .txt file
    output_file.write('Accuracy score: {:.3f}\n'.format(accuracy_score(labels, predictions)))
    confusion = confusion_matrix(labels, predictions)
    report = classification_report(labels, predictions, digits=5, output_dict=True)
    unwanted = {'accuracy', 'macro avg', 'weighted avg'}
    for unwanted_key in unwanted:
        del report[unwanted_key]
    f1_list = [report[key]['f1-score'] for key in report.keys()]
    f1_min_index = f1_list.index(min(f1_list))
    output_file.write(
        '\nEvaluation set confusion matrix for last iteration (columns are predictions):\n{}\n'.format(confusion))
    output_file.write('\nEvaluation set classification report for last iteration :\n{}\n'.format(
        classification_report(labels, predictions, digits=5)))
    output_file.write(
        'Minimum F1 value: {:.3f} at class {}\n\n'.format(f1_list[f1_min_index], list(report.keys())[f1_min_index]))
    # append point IDs and their predictions to the data_to_export array (this array will be saved later to the
    # validation .csv file)
    yearly_data_to_export = np.transpose(np.vstack((pIDs[:, 0], pIDs[:, 1], labelsT + 1,
                                                    predictionsT + 1))).tolist()  # shift labels to start from 0 instead of -1
    data_to_export += yearly_data_to_export

output_file.close()
# convert data_to_export to a numpy array and reformat it to have each point in a row with its associated prediction
# and reference data for multiple years in columns
data_to_export = np.array(data_to_export)
pIDs_list = np.unique(data_to_export[:, 0])
output_table = []
for ID in pIDs_list:
    row_to_add = [ID]
    for yr in validation_years:
        loc = np.where(np.logical_and(data_to_export[:, 0] == ID, data_to_export[:, 1] == yr))[0][0]
        row_to_add += [data_to_export[loc, 2], data_to_export[loc, 3]]
    output_table.append(row_to_add)
# convert it to dataframe to add column names and export validation data to a .csv file
output_table = pd.DataFrame(np.array(output_table), columns=columns_to_export)
output_table.to_csv(outputFolder + model_name + '_validation.csv', index=False)

